{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# @Author  : Wang Huanchen <11810419@mail.sustech.edu.cn>\n",
    "# @Time    : 2021/4/13 15:35\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Question 1\n",
    "HW2_1 = pd.read_csv('HW2_1_data.csv')\n",
    "\n",
    "# data preprocessing\n",
    "HW2_1 = HW2_1.dropna()\n",
    "HW2_1 = HW2_1[HW2_1['chlorides'] < 1]  #  There is a value of chlorides = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8699551569506726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import time\n",
    "\n",
    "# store the original column quality.\n",
    "tmp = HW2_1['quality'] \n",
    "\n",
    "# To improve the accuracy, use the bins to set two interval, and set new labels which are bad and good.\n",
    "bins = (4, 6.5, 8)\n",
    "group_names = ['bad', 'good']\n",
    "HW2_1['quality'] = pd.cut(HW2_1['quality'], bins = bins, labels = group_names)\n",
    "label_quality = LabelEncoder()\n",
    "HW2_1['quality'] = label_quality.fit_transform(HW2_1['quality']) # Now, the 5 and 6 labels are bad and the 7 label is good.\n",
    "\n",
    "# get the X and Y from the dataframe.\n",
    "X = HW2_1.drop('quality', axis = 1).iloc[:,:].values.reshape(-1,11)\n",
    "Y = HW2_1['quality'].values\n",
    "\n",
    "# standardize X.\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# split train and test datatset.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle=True, random_state = 30) \n",
    "# use shuffle can get random row, otherwise can just get pre-row, which make classify not accracy.\n",
    "\n",
    "# use the grid to find the best penalty coefficient and gamma.\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid= {'C': [0.8, 0.9, 1, 1.1, 1.2, 10], \n",
    "               'gamma': [0.8, 0.9, 1, 1.1 ,1.2,10, 100]},scoring = 'accuracy', cv=5)\n",
    "grid.fit(X_train, Y_train) \n",
    "\n",
    "# First Classifier.\n",
    "clf = SVC(kernel='rbf', C=grid.best_params_['C'], gamma=grid.best_params_['gamma']) \n",
    "# use the SVM Classifier with rbf kernel function.\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# get the accuracy.\n",
    "print(clf.score(X_test,Y_test)) \n",
    "\n",
    "# recover the column quality into the 5 6 7, Which wiil be used in the Second Classifier.\n",
    "HW2_1['quality'] = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# get the X and Y from the dataframe.\n",
    "X = HW2_1.iloc[:,:-1].values.reshape(-1,11)\n",
    "Y = HW2_1.iloc[:,-1:].values.reshape(-1)\n",
    "\n",
    "# split train and test datatset.\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(X,Y,test_size=0.2,shuffle=True)\n",
    "\n",
    "# Second classifier:\n",
    "clf_entropy = tree.DecisionTreeClassifier(criterion='entropy') # use the DecisonTree Classifier and the para -criterion = 'entropy'\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "\n",
    "# get the accuracy .\n",
    "print(clf_entropy.score(X_test,Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "HW2_2 = pd.read_csv('HW2_2_data.csv')\n",
    "\n",
    "# data preprocessing\n",
    "HW2_2 = HW2_2.dropna()\n",
    "X = HW2_2.iloc[:,:-1].values.reshape(-1,3)\n",
    "Y = HW2_2.iloc[:,-1:].values.reshape(-1)\n",
    "\n",
    "# standardize X\n",
    "X = StandardScaler().fit_transform(X) \n",
    "\n",
    "# split train and test datatset\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(X,Y,test_size=0.2,shuffle=True)\n",
    "\n",
    "# use the grid to find the best penalty coefficient and gamma\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid={\"C\":[0.1,1,10], \"gamma\":[0.001, 0.1, 1, 10]}, cv=5)\n",
    "grid.fit(X_train, Y_train) \n",
    "\n",
    "# Second Classifier\n",
    "clf = SVC(kernel='rbf', C=grid.best_params_['C'], gamma=grid.best_params_['gamma']) \n",
    "# use the SVM Classifier with rbf kernel function\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# get the accuracy\n",
    "print(clf.score(X_test,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
